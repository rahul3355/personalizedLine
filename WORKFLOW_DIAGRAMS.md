# Workflow & System Diagrams

## 1. User Journey: Upload to Download

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER FRONTEND (Next.js)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
                    â”Œâ”€ Step 0: File Upload â”€â”
                    â”‚ Drag & drop CSV/XLSX   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
                   POST /parse_headers (Stream to temp)
                   â† Headers, row_count, email_guess
                                    â†“
                    â”Œâ”€ Step 1: Select Email Column â”€â”
                    â”‚ Confirm or change column       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
                    â”Œâ”€ Step 2: Service Context â”€â”
                    â”‚ 6 fields (core_offer, etc) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
            POST /jobs (Create job, reserve credits atomically)
            â† job_id, status="queued"
                                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                BACKEND WORKER LOOP             â”‚
         â”‚ (Polls DB every 5 seconds for queued jobs)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
          process_job(job_id)
          â”œâ”€ Download input from Supabase storage
          â”œâ”€ Split into N chunks (WORKER_COUNT)
          â”œâ”€ For each chunk:
          â”‚  â””â”€ RQ Enqueue process_subjob(chunk_id)
          â”‚     (Runs in parallel if multiple workers)
          â””â”€ RQ Enqueue finalize_job(depends_on=[all subjobs])
                              â†“
    process_subjob(chunk_id) â€” RUNS IN PARALLEL
    â”œâ”€ For each row:
    â”‚  â”œâ”€ perform_research(email) â†’ call Serper, call Groq
    â”‚  â”œâ”€ generate_sif_personalized_line(research) â†’ call Groq
    â”‚  â””â”€ Write enriched CSV row
    â”œâ”€ Upload chunk CSV to outputs bucket
    â””â”€ Update progress atomically
                              â†“
    finalize_job (Starts when ALL subjobs complete)
    â”œâ”€ Download all chunk CSVs
    â”œâ”€ Merge into final DataFrame
    â”œâ”€ Convert to XLSX
    â”œâ”€ Upload to storage
    â””â”€ Mark job_status="succeeded"
                              â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    USER FRONTEND POLLS /jobs/{id}      â”‚
         â”‚  (Every 2 seconds checks progress %)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                  â”Œâ”€ Job Complete â”€â”
                  â”‚ Download XLSX  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Credit System Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               USER STARTS JOB CREATION                      â”‚
â”‚  (1000 rows, user has 800 credits remaining)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
    POST /jobs (with Redis lock acquisition)
                        â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Atomic Credit Reservation (Optimistic Concurrency)   â”‚
    â”‚                                                       â”‚
    â”‚ 1. Read: credits_remaining = 800                      â”‚
    â”‚ 2. Compare: 800 < 1000 rows needed                    â”‚
    â”‚ 3. Reject with 402 (insufficient credits)            â”‚
    â”‚                                                       â”‚
    â”‚ Response:                                             â”‚
    â”‚   {                                                   â”‚
    â”‚     "error": "insufficient_credits",                  â”‚
    â”‚     "credits_remaining": 800,                         â”‚
    â”‚     "missing_credits": 200                            â”‚
    â”‚   }                                                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
        User buys 1000 credits via Stripe
                        â†“
        Stripe Webhook: invoice.paid
        â†’ Append ledger entry (change: +1000)
        â†’ Update profiles: credits_remaining = 1800
                        â†“
        User retries job creation with same file
                        â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Atomic Credit Reservation (SUCCESS)                   â”‚
    â”‚                                                       â”‚
    â”‚ 1. Read: credits_remaining = 1800                     â”‚
    â”‚ 2. Compare: 1800 >= 1000 rows needed                  â”‚
    â”‚ 3. CAS Update:                                        â”‚
    â”‚    UPDATE profiles                                    â”‚
    â”‚    SET credits_remaining = 800                        â”‚
    â”‚    WHERE id = user_id                                 â”‚
    â”‚      AND credits_remaining = 1800                     â”‚
    â”‚ 4. If conflict, retry up to 5 times                   â”‚
    â”‚ 5. If success:                                        â”‚
    â”‚    â”œâ”€ Append ledger (change: -1000, reason: "job...")â”‚
    â”‚    â”œâ”€ Insert job (status: "queued")                   â”‚
    â”‚    â””â”€ Return job_id                                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
    Job enters processing pipeline...
                        â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ If Chunk Processing Fails:                            â”‚
    â”‚                                                       â”‚
    â”‚ refund_job_credits(job_id, user_id)                   â”‚
    â”‚   â”œâ”€ Check meta_json.credits_deducted = true          â”‚
    â”‚   â”œâ”€ Check meta_json.credits_refunded = false         â”‚
    â”‚   â”œâ”€ CAS refund: credits_remaining += 1000            â”‚
    â”‚   â”œâ”€ Append ledger (change: +1000, reason: "refund") â”‚
    â”‚   â””â”€ Set meta_json.credits_refunded = true            â”‚
    â”‚                                                       â”‚
    â”‚ Final: credits_remaining = 1800 (restored)            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Atomic Progress Update Pattern (Optimistic Concurrency)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Multiple process_subjob tasks updating same job      â”‚
â”‚  (e.g., Chunk 1, Chunk 2, Chunk 3 processing in parallel) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ _update_job_progress(job_id, total_rows, processed)      â”‚
â”‚                                                          â”‚
â”‚ Loop (max 5 attempts with 50ms backoff):                 â”‚
â”‚                                                          â”‚
â”‚ 1. READ:   SELECT rows_processed FROM jobs WHERE id=..   â”‚
â”‚    Result: rows_processed = 250                          â”‚
â”‚                                                          â”‚
â”‚ 2. CALC:   new_done = min(1000, 250 + 150) = 400       â”‚
â”‚            percent = (400 / 1000) * 100 = 40%           â”‚
â”‚                                                          â”‚
â”‚ 3. CAS:    UPDATE jobs                                   â”‚
â”‚            SET rows_processed = 400,                      â”‚
â”‚                progress_percent = 40.0                    â”‚
â”‚            WHERE id = job_id                             â”‚
â”‚              AND rows_processed = 250  â† MUST MATCH!     â”‚
â”‚                                                          â”‚
â”‚ 4a. If CAS succeeded (rows updated = 1):                 â”‚
â”‚     âœ… Return new_done=400, percent=40                   â”‚
â”‚                                                          â”‚
â”‚ 4b. If CAS failed (rows updated = 0):                    â”‚
â”‚     âš ï¸  Conflict! Another task updated it.                â”‚
â”‚     Retry from step 1 (read current value)              â”‚
â”‚                                                          â”‚
â”‚ 5. If 5 attempts fail:                                   â”‚
â”‚     ğŸš« FATAL: Progress update failed, chunk fails         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Example of concurrent updates:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunk 1: rows_processed=250 â†’ attempt 1st update       â”‚
â”‚          CAS: 250â†’400 âœ… SUCCESS                        â”‚
â”‚                                                        â”‚
â”‚ Chunk 2: rows_processed=250 â†’ attempt 1st update       â”‚
â”‚          CAS: 250â†’??? âŒ CONFLICT (Chunk1 changed it!)  â”‚
â”‚          Retry: READ rows_processed â†’ now 400           â”‚
â”‚          CAS: 400â†’550 âœ… SUCCESS                        â”‚
â”‚                                                        â”‚
â”‚ Chunk 3: rows_processed=250 â†’ attempt 1st update       â”‚
â”‚          CAS: 250â†’??? âŒ CONFLICT                        â”‚
â”‚          Retry: READ rows_processed â†’ now 550           â”‚
â”‚          CAS: 550â†’700 âœ… SUCCESS                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Research & Personalization Pipeline (Per Row)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Row: {name: "John", company: "Acme", email: "john@..."}   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
    â”Œâ”€ perform_research("john@acme.com") â”€â”
    â”‚                                      â”‚
    â”‚ 1. Validate: "@" present âœ“           â”‚
    â”‚                                      â”‚
    â”‚ 2. Split: "john" + "acme.com"        â”‚
    â”‚                                      â”‚
    â”‚ 3. Serper API Call #1:               â”‚
    â”‚    Query: "john acme.com"            â”‚
    â”‚    Response: [{title, snippet}, ...] â”‚
    â”‚                                      â”‚
    â”‚ 4. Serper API Call #2:               â”‚
    â”‚    Query: "acme.com"                 â”‚
    â”‚    Response: [{title, snippet}, ...] â”‚
    â”‚                                      â”‚
    â”‚ 5. Extract findings:                 â”‚
    â”‚    findings = [                      â”‚
    â”‚      "John is VP at Acme...",        â”‚
    â”‚      "Acme raised Series B...",      â”‚
    â”‚      "Acme works in SaaS..."         â”‚
    â”‚    ]                                 â”‚
    â”‚                                      â”‚
    â”‚ 6. Groq API Call (synthesis):        â”‚
    â”‚    Prompt: "You are a sales...       â”‚
    â”‚    Findings: [above]                 â”‚
    â”‚    Email: john@acme.com              â”‚
    â”‚    Response:                         â”‚
    â”‚    {                                 â”‚
    â”‚      "person": {                     â”‚
    â”‚        "name": "John Smith",         â”‚
    â”‚        "info": [                     â”‚
    â”‚          "VP of Sales at Acme",      â”‚
    â”‚          "15+ years B2B SaaS exp"    â”‚
    â”‚        ]                             â”‚
    â”‚      },                              â”‚
    â”‚      "company": {                    â”‚
    â”‚        "name": "Acme Inc",           â”‚
    â”‚        "info": [                     â”‚
    â”‚          "Raised $50M Series B",     â”‚
    â”‚          "300+ enterprise customers" â”‚
    â”‚        ],                            â”‚
    â”‚        "moat": "Strong brand & team" â”‚
    â”‚      }                               â”‚
    â”‚    }                                 â”‚
    â”‚                                      â”‚
    â”‚ 7. Validate JSON structure âœ“         â”‚
    â”‚                                      â”‚
    â”‚ 8. Return: (full JSON string)        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
    â”Œâ”€ generate_sif_personalized_line(...) â”€â”
    â”‚                                        â”‚
    â”‚ Input: research_json (from above)      â”‚
    â”‚        service_context = {             â”‚
    â”‚          "core_offer": "AI email...",  â”‚
    â”‚          "key_differentiator": "...",  â”‚
    â”‚          "timeline": "Next Thursday"   â”‚
    â”‚        }                               â”‚
    â”‚                                        â”‚
    â”‚ 1. Parse research JSON âœ“               â”‚
    â”‚                                        â”‚
    â”‚ 2. Build system prompt:                â”‚
    â”‚    "Generate human-written...          â”‚
    â”‚     Focus on pain point...             â”‚
    â”‚     Keep < 25 words per sentence"      â”‚
    â”‚                                        â”‚
    â”‚ 3. Build user prompt:                  â”‚
    â”‚    "{system_prompt}                    â”‚
    â”‚     Person info: {research JSON}       â”‚
    â”‚     Service: {core_offer...}"          â”‚
    â”‚                                        â”‚
    â”‚ 4. Groq API Call (personalization):    â”‚
    â”‚    model: "openai/gpt-oss-120b"        â”‚
    â”‚    temperature: 0.6                    â”‚
    â”‚    Response:                           â”‚
    â”‚    "Noticed Acme just hit 300          â”‚
    â”‚     customersâ€”congrats! We help        â”‚
    â”‚     SaaS teams scale outreach in       â”‚
    â”‚     half the time. Demo next Thu?"     â”‚
    â”‚                                        â”‚
    â”‚ 5. Extract content âœ“                   â”‚
    â”‚                                        â”‚
    â”‚ 6. Return: (personalized line string)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
    Write to CSV:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ name | company | email | sif_research â”‚ sif_personalized â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ John â”‚ Acme | john@... â”‚ {full JSON} â”‚ "Noticed Acme..." â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. Stripe Webhook Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User clicks "Upgrade to Starter" on /billing         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
    POST /create_checkout_session
    â”œâ”€ Ensure Stripe customer exists
    â”œâ”€ Create Stripe Checkout session
    â”‚  (redirects to Stripe-hosted form)
    â””â”€ Return: { "id": "cs_..." }
                  â†“
    Browser redirects to Stripe Checkout
    (user enters card, completes payment)
                  â†“
    Stripe sends webhooks to POST /stripe/webhook
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Event: checkout.session.completed                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Verify webhook signature (STRIPE_WEBHOOK_SECRET)    â”‚
â”‚ 2. Extract customer_id & subscription_id from metadata â”‚
â”‚ 3. Create/sync Stripe customer                         â”‚
â”‚ 4. sync_stripe_customer(customer_id)                   â”‚
â”‚    â””â”€ Fetch subscription details from Stripe          â”‚
â”‚ 5. Update profiles table:                              â”‚
â”‚    â”œâ”€ plan_type = "starter"                            â”‚
â”‚    â”œâ”€ credits_remaining += 2000                        â”‚
â”‚    â”œâ”€ subscription_status = "active"                   â”‚
â”‚    â””â”€ renewal_date = (30 days from now)               â”‚
â”‚ 6. Append ledger:                                      â”‚
â”‚    change: +2000, reason: "purchase: starter"         â”‚
â”‚ 7. Return 200 OK (idempotent)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Event: customer.subscription.updated                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ (e.g., user downgrades from Pro â†’ Starter)           â”‚
â”‚ 1. Verify webhook signature                         â”‚
â”‚ 2. sync_stripe_customer()                            â”‚
â”‚ 3. Update profiles:                                  â”‚
â”‚    â”œâ”€ plan_type = "starter"                         â”‚
â”‚    â”œâ”€ subscription_status = "active"                â”‚
â”‚    â””â”€ renewal_date = (next period end)              â”‚
â”‚ 4. Return 200 OK                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Event: customer.subscription.deleted                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ (user cancelled subscription)                       â”‚
â”‚ 1. Verify webhook signature                         â”‚
â”‚ 2. Update profiles:                                 â”‚
â”‚    â””â”€ subscription_status = "inactive"              â”‚
â”‚ 3. Don't touch credits (already spent)              â”‚
â”‚ 4. Return 200 OK                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
    Frontend: user sees updated:
    â”œâ”€ credits_remaining
    â”œâ”€ plan_type
    â”œâ”€ subscription_status
    â””â”€ renewal_date
```

---

## 6. File Storage Structure

```
Supabase Storage
â”œâ”€â”€ inputs/ (Raw uploads)
â”‚   â””â”€â”€ {user_id}/
â”‚       â””â”€â”€ {job_id}/
â”‚           â”œâ”€â”€ input.csv (Original upload)
â”‚           â””â”€â”€ raw_chunks/
â”‚               â”œâ”€â”€ chunk_1.csv (500 rows)
â”‚               â”œâ”€â”€ chunk_2.csv (500 rows)
â”‚               â””â”€â”€ chunk_3.csv (50 rows)
â”‚
â””â”€â”€ outputs/ (Processing results)
    â””â”€â”€ {user_id}/
        â””â”€â”€ {job_id}/
            â”œâ”€â”€ chunk_1.csv (enriched chunk)
            â”œâ”€â”€ chunk_2.csv (enriched chunk)
            â”œâ”€â”€ chunk_3.csv (enriched chunk)
            â””â”€â”€ result.xlsx (final merged)

Local Filesystem (Worker nodes)
â”œâ”€â”€ /data/raw_chunks/
â”‚   â””â”€â”€ {job_id}/
â”‚       â”œâ”€â”€ chunk_1.csv (temp during chunking)
â”‚       â”œâ”€â”€ chunk_2.csv
â”‚       â””â”€â”€ chunk_3.csv
â”‚
â””â”€â”€ /data/chunks/
    â””â”€â”€ {job_id}/
        â”œâ”€â”€ chunk_1.csv (temp during processing)
        â”œâ”€â”€ chunk_2.csv
        â”œâ”€â”€ chunk_3.csv
        â””â”€â”€ (cleaned up after finalize)
```

---

## 7. Job Status State Machine

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     QUEUED       â”‚
                    â”‚ (waiting in DB)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   IN_PROGRESS        â”‚
                  â”‚ (process_job started)â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                                         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ SUCCEEDED   â”‚                        â”‚   FAILED     â”‚
    â”‚ (all chunks â”‚                        â”‚ (error in    â”‚
    â”‚  processed) â”‚                        â”‚  any step)   â”‚
    â”‚ result_path â”‚                        â”‚ error: "..." â”‚
    â”‚ filled      â”‚                        â”‚ credits      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚ refunded     â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Error scenarios:
â”œâ”€ Missing file_path â†’ FAILED immediately
â”œâ”€ Credit deduction fails â†’ FAILED before processing
â”œâ”€ Chunk process_subjob fails â†’ FAILED + refund
â”œâ”€ Finalize fails â†’ FAILED + refund
â””â”€ Unhandled exception â†’ FAILED + refund
```

